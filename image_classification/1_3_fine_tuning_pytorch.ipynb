{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-3_fine_tuning_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yohk2291/MachineLearning/blob/master/image_classification/1_3_fine_tuning_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwA65TbpLNuI",
        "colab_type": "code",
        "outputId": "17d2d44a-7a0c-43c4-cc08-b8619270d2b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!git clone https://github.com/Yohk2291/MachineLearning.git\n",
        "%cd MachineLearning/\n",
        "%cd image_classification/"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MachineLearning'...\n",
            "remote: Enumerating objects: 65, done.\u001b[K\n",
            "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 65 (delta 22), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (65/65), done.\n",
            "/content/MachineLearning/image_classification/MachineLearning\n",
            "/content/MachineLearning/image_classification/MachineLearning/image_classification\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9dsU11IXkn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QCvW2cJXoDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# フォルダ「data」が存在しない場合は作成する\n",
        "data_dir = \"./data/\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsIfH5AAXfHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# アリとハチの画像データをダウンロードし解凍\n",
        "# PyTorchのチュートリアルで用意されているものです\n",
        "# https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
        "\n",
        "url = \"https://download.pytorch.org/tutorial/hymenoptera_data.zip\"\n",
        "save_path = os.path.join(data_dir, \"hymenoptera_data.zip\")\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    urllib.request.urlretrieve(url, save_path)\n",
        "\n",
        "    # ZIPファイルを読み込み\n",
        "    zip = zipfile.ZipFile(save_path)\n",
        "    zip.extractall(data_dir)  # ZIPを解凍\n",
        "    zip.close()  # ZIPファイルをクローズ\n",
        "\n",
        "    # ZIPファイルを消去\n",
        "    os.remove(save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tomWkSXOk1XJ",
        "colab_type": "text"
      },
      "source": [
        "## 各種パッケージのインポート"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlDF4putMiv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import numpy as np\n",
        "import json \n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rrWG12Ek_7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 乱数のシードを設定\n",
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kM0TZEYCN3f8",
        "colab_type": "code",
        "outputId": "c1ed8575-bf30-44e2-881d-5c8d54964ba4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"PyTorch Version\", torch.__version__)\n",
        "print(\"Torchvision Version\", torchvision.__version__)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch Version 1.1.0\n",
            "Torchvision Version 0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtEldZ15l_ZO",
        "colab_type": "text"
      },
      "source": [
        "## Datasetの作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zY4rB4LmD-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 訓練時と推論時で異なる前処理を実行\n",
        "class ImageTransform():\n",
        "  def __init__(self, resize, mean, std):\n",
        "    self.data_transform = {\n",
        "        'train' : transforms.Compose([\n",
        "                transforms.RandomResizedCrop(resize, scale=(0.5, 1.0)), # 0.5-1.0の間で画像を拡大・縮小\n",
        "                transforms.RandomHorizontalFlip(), # 画像の左右を50%の確率で反転\n",
        "                transforms.ToTensor(), # テンソルに変換\n",
        "                transforms.Normalize(mean, std) # 標準化\n",
        "                ]),\n",
        "        'val' : transforms.Compose([\n",
        "               transforms.Resize(resize), # 短辺の長さがresizeの大きさになる\n",
        "               transforms.CenterCrop(resize), # 画像の中心をresize * resizeで切り取る\n",
        "               transforms.ToTensor(), # テンソルに変換\n",
        "               transforms.Normalize(mean, std) # 標準化\n",
        "               ])\n",
        "    }\n",
        "    \n",
        "  def __call__(self, img, phase='train'):\n",
        "    return self.data_transform[phase](img) # phaseでtrain or val を指定"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zaulebkpkV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# アリとハチの画像へのファイルパスのリストを作成する\n",
        "\n",
        "\n",
        "def make_datapath_list(phase=\"train\"):\n",
        "    \"\"\"\n",
        "    データのパスを格納したリストを作成する。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    phase : 'train' or 'val'\n",
        "        訓練データか検証データかを指定する\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    path_list : list\n",
        "        データへのパスを格納したリスト\n",
        "    \"\"\"\n",
        "\n",
        "    rootpath = \"./data/hymenoptera_data/\"\n",
        "    target_path = osp.join(rootpath+phase+'/**/*.jpg')\n",
        "    print(target_path)\n",
        "\n",
        "    path_list = []  # ここに格納する\n",
        "\n",
        "    # globを利用してサブディレクトリまでファイルパスを取得する\n",
        "    for path in glob.glob(target_path):\n",
        "        path_list.append(path)\n",
        "\n",
        "    return path_list\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRLv5PF8J3Nf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9e097a1a-37bf-4439-ec3c-afd58cd7d462"
      },
      "source": [
        "# 実行\n",
        "train_list = make_datapath_list(phase=\"train\")\n",
        "val_list = make_datapath_list(phase=\"val\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./data/hymenoptera_data/train/**/*.jpg\n",
            "./data/hymenoptera_data/val/**/*.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBDOIdmnqCV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HymenopteraDataset(data.Dataset):\n",
        "  \"\"\"\n",
        "    アリとハチの画像のDatasetクラス。PyTorchのDatasetクラスを継承。\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    file_list : リスト\n",
        "        画像のパスを格納したリスト\n",
        "    transform : object\n",
        "        前処理クラスのインスタンス\n",
        "    phase : 'train' or 'test'\n",
        "        学習か訓練かを設定する。\n",
        "    \"\"\"\n",
        "\n",
        "  def __init__(self, file_list, transform=None, phase='train'):\n",
        "    self.file_list = file_list  # ファイルパスのリスト\n",
        "    self.transform = transform  # 前処理クラスのインスタンス\n",
        "    self.phase = phase  # train or valの指定\n",
        "\n",
        "  def __len__(self):\n",
        "    '''画像の枚数を返す'''\n",
        "    return len(self.file_list)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    '''前処理をした画像のTensor形式のデータとラベルを取得'''\n",
        "    # index番目の画像をロード\n",
        "    img_path = self.file_list[index]\n",
        "    img = Image.open(img_path)  # [高さ][幅][色RGB]\n",
        "\n",
        "    # 画像の前処理を実施\n",
        "    img_transformed = self.transform(img, self.phase)  # torch.Size([3, 224, 224])\n",
        "\n",
        "    # 画像のラベルをファイル名から抜き出す\n",
        "    if self.phase == \"train\":\n",
        "      label = img_path[30:34]\n",
        "    elif self.phase == \"val\":\n",
        "      label = img_path[28:32]\n",
        "\n",
        "    # ラベルを数値に変更する\n",
        "    if label == \"ants\":\n",
        "      label = 0\n",
        "    elif label == \"bees\":\n",
        "      label = 1\n",
        "\n",
        "    return img_transformed, label\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyaJxO59JvTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataset作成\n",
        "size = 224\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "\n",
        "train_dataset = HymenopteraDataset(\n",
        "    file_list=train_list, transform=ImageTransform(size, mean, std), phase='train')\n",
        "\n",
        "val_dataset = HymenopteraDataset(\n",
        "    file_list=val_list, transform=ImageTransform(size, mean, std), phase='val')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdE0TX2-sL5D",
        "colab_type": "text"
      },
      "source": [
        "## DataLoaderを作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE79lxkRsLMS",
        "colab_type": "code",
        "outputId": "80fd72cc-1f31-42e8-9c20-78a7433e54e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# ミニバッチのサイズ\n",
        "batch_size = 32\n",
        "\n",
        "# DataLoaderの作成\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# 辞書型変数にまとめる\n",
        "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
        "\n",
        "\n",
        "# 動作確認\n",
        "batch_iterator = iter(dataloaders_dict[\"train\"])\n",
        "inputs, labels = next(\n",
        "    batch_iterator)\n",
        "\n",
        "print(inputs.size())\n",
        "print(labels)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 3, 224, 224])\n",
            "tensor([0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
            "        1, 0, 1, 1, 1, 1, 1, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KLCbwC6y8ol",
        "colab_type": "text"
      },
      "source": [
        "## ネットワークモデルの作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teSF85Hey7vm",
        "colab_type": "code",
        "outputId": "b1b69888-d2c6-4924-d0b0-0c7e312e54ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "# 学習済みVGG-16をロード\n",
        "use_pretrained = True #学習済みパラメータを使用\n",
        "net = models.vgg16(pretrained=use_pretrained)\n",
        "\n",
        "# VGG-16の最後の出力層の出力ユニットをアリとハチの２つに付け替える \n",
        "net.classifier[6] = nn.Linear(in_features=4096, out_features=2) # out_features: 1000 -> 2\n",
        "\n",
        "# 訓練モードに設定\n",
        "net.train()\n",
        "print(net)\n",
        "print('ネットワーク設定完了：学習済みの重みをロードし、訓練モードに設定しました')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace)\n",
            "    (2): Dropout(p=0.5)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.5)\n",
            "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
            "  )\n",
            ")\n",
            "ネットワーク設定完了：学習済みの重みをロードし、訓練モードに設定しました\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MU7bAh40d4V",
        "colab_type": "text"
      },
      "source": [
        "## 損失関数を定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXY5L3E8y5_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# クロスエントロピー誤差\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-4XXSPDKi8L",
        "colab_type": "text"
      },
      "source": [
        "※　ここまで1-2_transfer_learningと共通"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pOyAg280zsz",
        "colab_type": "text"
      },
      "source": [
        "## 最適化手法の設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5sAtlnY0t3X",
        "colab_type": "code",
        "outputId": "b506f500-3b55-4214-a926-696614e2997b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "# ファインチューニングで学習させるパラメータを格納\n",
        "params_to_update_1 = []\n",
        "params_to_update_2 = []\n",
        "params_to_update_3 = []\n",
        "\n",
        "# 学習させるパラメータ\n",
        "update_param_names_1 = [\"features\"]\n",
        "update_param_names_2 = [\"classifier.0.weight\", \"classifier.0.bias\", \"classifier.3.weight\", \"classifier.3.bias\"]\n",
        "update_param_names_3 = [\"classifier.6.weight\", \"classifier.6.bias\"]\n",
        "\n",
        "# 学習させるパラメータ以外は変化させない\n",
        "for name, param in net.named_parameters():\n",
        "  if update_param_names_1[0] in name:\n",
        "    param.requires_grad = True\n",
        "    params_to_update_1.append(param)\n",
        "    print(\"params_to_update_1に格納:\", name)\n",
        "\n",
        "  elif name in update_param_names_2:\n",
        "    param.requires_grad = True\n",
        "    params_to_update_2.append(param)\n",
        "    print(\"params_to_update_2に格納:\", name)\n",
        "\n",
        "  elif name in update_param_names_3:\n",
        "    param.requires_grad = True\n",
        "    params_to_update_3.append(param)\n",
        "    print(\"params_to_update_3に格納:\", name)\n",
        "\n",
        "  else:\n",
        "    param.requires_grad = False\n",
        "    print(\"勾配計算なし:\", name)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "params_to_update_1に格納: features.0.weight\n",
            "params_to_update_1に格納: features.0.bias\n",
            "params_to_update_1に格納: features.2.weight\n",
            "params_to_update_1に格納: features.2.bias\n",
            "params_to_update_1に格納: features.5.weight\n",
            "params_to_update_1に格納: features.5.bias\n",
            "params_to_update_1に格納: features.7.weight\n",
            "params_to_update_1に格納: features.7.bias\n",
            "params_to_update_1に格納: features.10.weight\n",
            "params_to_update_1に格納: features.10.bias\n",
            "params_to_update_1に格納: features.12.weight\n",
            "params_to_update_1に格納: features.12.bias\n",
            "params_to_update_1に格納: features.14.weight\n",
            "params_to_update_1に格納: features.14.bias\n",
            "params_to_update_1に格納: features.17.weight\n",
            "params_to_update_1に格納: features.17.bias\n",
            "params_to_update_1に格納: features.19.weight\n",
            "params_to_update_1に格納: features.19.bias\n",
            "params_to_update_1に格納: features.21.weight\n",
            "params_to_update_1に格納: features.21.bias\n",
            "params_to_update_1に格納: features.24.weight\n",
            "params_to_update_1に格納: features.24.bias\n",
            "params_to_update_1に格納: features.26.weight\n",
            "params_to_update_1に格納: features.26.bias\n",
            "params_to_update_1に格納: features.28.weight\n",
            "params_to_update_1に格納: features.28.bias\n",
            "params_to_update_2に格納: classifier.0.weight\n",
            "params_to_update_2に格納: classifier.0.bias\n",
            "params_to_update_2に格納: classifier.3.weight\n",
            "params_to_update_2に格納: classifier.3.bias\n",
            "params_to_update_3に格納: classifier.6.weight\n",
            "params_to_update_3に格納: classifier.6.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Hk6naal2aAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 最適化手法の設定(MomentumSGD)\n",
        "optimizer = optim.SGD([{'params':params_to_update_1, 'lr': 1e-4},\n",
        "                        {'params':params_to_update_2, 'lr': 5e-4},\n",
        "                        {'params':params_to_update_3, 'lr': 1e-4}\n",
        "                        ], momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOOLIHTw2v45",
        "colab_type": "text"
      },
      "source": [
        "## 学習・検証"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmhiuUpb2zGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "  # GPUが使えるかの確認\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(\"使用デバイス：\", device)\n",
        "  \n",
        "  # ネットワークをGPUへ\n",
        "  net.to(device)\n",
        "  \n",
        "  torch.backends.cudnn.benchmark = True\n",
        "\n",
        "\n",
        "  # epochのループ\n",
        "  for epoch in range(num_epochs):\n",
        "    print('Epoch{}/{}'.format(epoch+1, num_epochs))\n",
        "    print('-'*80)\n",
        "\n",
        "    # epoch毎の学習と検証のループ\n",
        "    for phase in ['train', 'val']:\n",
        "      if phase == 'train':\n",
        "        net.train() # 訓練モードにする\n",
        "      else:\n",
        "        net.eval() # 検証モードにする\n",
        "\n",
        "      epoch_loss = 0.0 # epochの損失和\n",
        "      epoch_corrects = 0 # epochの正解数\n",
        "\n",
        "      # 学習前の性能を確かめるため、epoch=0での訓練は省略\n",
        "      if (epoch == 0) and (phase == 'train'):\n",
        "        continue\n",
        "      \n",
        "      # dataloaderからミニバッチを取り出す\n",
        "      for inputs, labels in tqdm(dataloaders_dict[phase]):\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # optimizer を初期化\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 順伝播\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "          outputs = net(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          _, preds = torch.max(outputs, 1)\n",
        "\n",
        "          # 訓練時は逆伝播も\n",
        "          if phase == 'train':\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "          # lossの合計を更新\n",
        "          epoch_loss += loss.item() * inputs.size(0)\n",
        "          # 正解数の合計を更新\n",
        "          epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "      # epoch毎のlossと正解率を出力\n",
        "      epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "      epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "      print('{} Loss: {:.4f}, Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXZGCM4C74Yn",
        "colab_type": "code",
        "outputId": "c19eb493-3e54-422f-ad0e-3f05a897137d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "# 学習・検証を実行\n",
        "num_epochs = 5\n",
        "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "使用デバイス： cuda:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch1/5\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:04<00:00,  1.09s/it]\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.8070, Acc: 0.3595\n",
            "Epoch2/5\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:09<00:00,  1.58s/it]\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.7463, Acc: 0.5144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:01<00:00,  2.84it/s]\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.5137, Acc: 0.8170\n",
            "Epoch3/5\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4473, Acc: 0.8066\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:01<00:00,  2.87it/s]\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.3021, Acc: 0.9216\n",
            "Epoch4/5\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.2604, Acc: 0.9136\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:01<00:00,  2.83it/s]\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.2145, Acc: 0.9412\n",
            "Epoch5/5\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.1941, Acc: 0.9424\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:01<00:00,  2.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.1754, Acc: 0.9477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDL0DV0WPdDS",
        "colab_type": "text"
      },
      "source": [
        "## 学習したネットワークの保存・ロード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POIVJkJ8alLH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ネットワークパラメータの保存\n",
        "save_path = './weights_fine_tuning.pth'\n",
        "torch.save(net.state_dict(), save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yjb3AKgP3FU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab420143-fa11-40b9-839a-7d488808fed4"
      },
      "source": [
        "# ネットワークパラメータのロード\n",
        "load_path = './weights_fine_tuning.pth'\n",
        "load_weights = torch.load(load_path)\n",
        "net.load_state_dict(load_weights)\n",
        "\n",
        "# GPU上で保存された重みをCPU上でロードする場合\n",
        "'''load_weights = torch.load(load_path, map_location={'cuda:0': 'cpu'})\n",
        "net.load_state_dict(load_weights)\n",
        "'''"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"load_weights = torch.load(load_path, map_location={'cuda:0': 'cpu'})\\nnet.load_state_dict(load_weights)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWSjqyzzQoaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}